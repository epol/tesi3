\documentclass[a4paper,10pt]{amsbook}

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8x]{inputenc}
\usepackage[italian]{babel}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xfrac}
\usepackage[all]{xy}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\usepackage{fullpage}
\usepackage{hyperref}



%\setlength{\parindent}{0in}

\newcounter{counter1}

\theoremstyle{plain}
\newtheorem{myteo}[counter1]{Teorema}
\newtheorem{mylem}[counter1]{Lemma}
\newtheorem{mypro}[counter1]{Proposizione}
\newtheorem{mycor}[counter1]{Corollario}
\newtheorem*{myteo*}{Teorema}
\newtheorem*{mylem*}{Lemma}
\newtheorem*{mypro*}{Proposizione}
\newtheorem*{mycor*}{Corollario}

\theoremstyle{definition}
\newtheorem{mydef}[counter1]{Definizione}
\newtheorem{myes}[counter1]{Esempio}
\newtheorem{myex}[counter1]{Esercizio}
\newtheorem*{mydef*}{Definizione}
\newtheorem*{myes*}{Esempio}
\newtheorem*{myex*}{Esercizio}

\theoremstyle{remark}
\newtheorem{mynot}[counter1]{Nota}
\newtheorem{myoss}[counter1]{Osservazione}
\newtheorem*{mynot*}{Nota}
\newtheorem*{myoss*}{Osservazione}


\newcommand{\obar}[1]{\overline{#1}}
\newcommand{\ubar}[1]{\underline{#1}}

\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\pa}[1]{\left(#1\right)}
\newcommand{\ang}[1]{\left<#1\right>}
\newcommand{\bra}[1]{\left[#1\right]}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}

\newcommand{\pfrac}[2]{\pa{\frac{#1}{#2}}}
\newcommand{\bfrac}[2]{\bra{\frac{#1}{#2}}}
\newcommand{\psfrac}[2]{\pa{\sfrac{#1}{#2}}}
\newcommand{\bsfrac}[2]{\bra{\sfrac{#1}{#2}}}

\newcommand{\der}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pder}[2]{\pfrac{\partial #1}{\partial #2}}
\newcommand{\sder}[2]{\sfrac{\partial #1}{\partial #2}}
\newcommand{\psder}[2]{\psfrac{\partial #1}{\partial #2}}

\newcommand{\intl}{\int \limits}

\DeclareMathOperator{\de}{d}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\len}{len}

\DeclareMathOperator{\gl}{GL}
\DeclareMathOperator{\aff}{Aff}
\DeclareMathOperator{\isom}{Isom}

\DeclareMathOperator{\im}{Im}




\title{Tesi}
\author{Enrico Polesel}
\date{\today}

\begin{document}
\maketitle

\setcounter{tocdepth}{5}

\tableofcontents

\chapter{Camminimi minimi su grafi}

\begin{mydef}[Grafo]
  Chiamiamo grafo la coppia $G = (V,E)$ dove $V$ è un insieme finito
  di elementi detti \textit{nodi} e $E\subseteq V \times V$ di
  relazioni chiamate archi.
\end{mydef}

Se non specificato diversamente definiamo $N = \abs{V}$ e $M =
\abs{E}$.

Diciamo che gli archi di un grafo sono pesati se esiste una funzione
\textit{peso}
\[ w : E \rightarrow \mathbb{R} \]
Per noi il peso di un arco rappresenta la sua lunghezza, per questo
chiameremo con \textit{lunghezza di un arco} il suo peso.

Nel caso non pesato ci riconduciamo al caso pesato prendendo $w$
costante a $1$.

Siamo interessati a considerare grafi diretti, cioè gli archi sono
orientati, nel caso indiretto possiamo ridurci a questo caso
considerando l'insieme di archi 
\[ V' = V \cup \set{ (w,v) \mid (v,w) \in V } \]

\section{Proprietà dei cammini minimi}

\begin{mydef}[Cammino]
  Chiamiamo \textit{cammino} sul grafo $G$ una successione ordinata
  finita di nodi $p = ( v_0, v_1, ..., v_k)$ tale che 
  \[ \forall i \in \set{ 1, ... , k} \;\;\; (v_{i-1}, v_{i} ) \in E\]
\end{mydef}

Diciamo che $p$ congiunge $v_0$ a $v_k$. Dati due nodi $v,w$ chiamiamo
$P(v,w)$ l'insieme (eventualmente vuoto) dei cammini che congiungono
$v$ a $w$

Dati due cammini $p = ( v_0, v_1, ..., v_k)$ e $q = ( w_0, w_1, ...,
w_{h})$ tali che $v_k = w_0$ chiamiamo somma dei due cammini il
cammino
\[ p+q = ( v_0, v_1, ..., v_k= w_0, w_1, ..., w_{h}) \]

Dato un cammino $p = ( v_0, v_1, ..., v_k)$ chiamiamo
\textit{sottocammino} di $p$ un cammino $q = ( v_i , v_{i+1}, ... ,
v_j )$ con $0 \le i \le j \le k$.

\begin{mydef}[Lunghezza di un cammino]
  Chiamiamo lunghezza di un cammino $p$ la quantità
  \[ w(p) = \sum _{i=1} ^k w \pa{ (v_{i-1}, v_i) } \]
\end{mydef}

Osserivamo che la lunghezza della somma di due cammini è uguale alla
somma delle lunghezze.

Siamo interessati a trattare grafi in cui gli archi hanno lunghezza
non negativa, per cui da ora usiamo l'ipotesi $\forall e \in E \; w(e)
\ge 0$.

\begin{mydef}[Distanza di due punti]
  \[ \delta(v,w) = \left\{
    \begin{matrix}
      \min \limits_{p \in P(v,w)} { w(p) } & \; P(v,w) \neq \emptyset \\
      \infty & \; P(v,w) = \emptyset
    \end{matrix}
    \right.
    \]
\end{mydef}

Per $P(v,w) \neq \emptyset$ chiamiamo \textit{cammino minimo} fra $v$
e $w$ un cammino la cui lunghezza realizza il minimo.

Osserviamo che questa distanza verifica le proprietà
\begin{itemize}
\item $\delta(v,v) = 0$ infatti il cammino $(v)$ ha lunghezza $0$
\item $\delta(v,z) \le \delta(v,w) + \delta(w,z)$ infatti sommando il
  cammino minimo tra $v$ e $w$ e quello tra $w$ e $z$ si ottiene un
  cammino in $P(v,z)$
\end{itemize}
Questa distanza, però, in generale non è simmetica, quindi definisce
una pseudometrica. Nel caso di grafi non orientati allora $\delta$
diventa una distanza.

Osserviamo inoltre che
\begin{itemize}
\item Ogni sottocammino di un cammino minimo è ancora minimo
\item Possiamo sempre scegliere un cammino minimo aciclico, infatti i
  cicli contenuti in un cammino minimo devono avere lunghezza nulla
  (visto che lavoriamo in ipotesi di lunghezze non negative) e quindi
  può essere eliminato
\end{itemize}

\section{Cammini minimi da una sorgente unica}

Fissiamo un nodo $s \in V$ che chiameremo sorgente. Siamo interessati
a calcolare:
\begin{itemize}
\item le distanze $\delta(s,v)$ al variare di $v\in V$
\item i cammini minimi tra $s$ ed ogni nodo $v\in V$
\end{itemize}

Possiamo costruire il grafo dei cammini minimi con sorgente in $s$ che
chiamiamo $G_s = (V,E_s)$ dove
\[ E_s = \set{ e\in E | e\text{ compare in un cammino minimo con
    sorgente }s} \]

Questo grafo rappresenta tutti i cammini minimi con sorgente $s$.

\begin{mypro}
  Se gli archi hanno lunghezza strettamente positiva $G_s$ definito
  come sopra è un DAG (grafo aciclico diretto)
\end{mypro}
\begin{proof}
  Supponiamo, per assurdo, che esista un ciclo $(v_0,v_1,...,v_k)$ e
  siano rispettivamente $d_0,d_1,...,d_k$ le distanze di questi nodi
  dalla sorgente $s$.

  Per ogni arco $(v_{i-1},v_i)$ abbiamo supposto che esista un cammino
  minimo che lo attraversi, troncando questo cammino otteniamo un
  cammino minimo da $s$ a $v_i$ e, troncandolo ulteriormente, un
  cammino minimo da $s$ a $v_{i-1}$. Quindi
  \[ d_k = d_{k-1} + w\pa{ (v_{i-1} , v_i ) } \Rightarrow d_i >
  d_{i-1} \]
  
  Applicando lo stesso argomento all'arco $(v_k,v_0)$ otteniamo $d_0 >
  d_k$. Unendo queste disuguaglianze otteniamo
  \[ d_0 < d_1 < \dots < d_k < d_0 \Rightarrow d_0 < d_0 \]
  Assurdo.
\end{proof}

Se invece scegliamo (in modo opportuno) un cammino minimo per ogni
nodo otteniamo un albero di cammini minimi. Per ottenere questa
struttura procediamo in modo induttivo

\textbf{Caso base:} inseriamo la sorgente $s$ nell'albero

\textbf{Passo induttivo:} scegliamo un nodo $v$ non ancora incluso
nell'albero, sia $\tilde p = (s=v_0,v_1,..., v_{k-1}, v_k=v)$ un cammino minimo da
$s$ a $v$. Prendiamo ora $h = \max\set{ i \mid v_i \text{ appartiene
    all'albero}}$ e $q$ il cammino minimo nell'albero da $s$ a
$v_h$. Allora $p = q + (v_{h+1}, \dots , v)$ è un cammino minimo da $s$ a
$v$, aggiungiamo i nodi $\pa{ v_i } _{i>h}$ e gli archi
  $\pa{(v_{i-1},v_i)}_{i>h}$ all'albero.

Osserviamo che nel passo induttivo non abbiamo aggiunto nessun ciclo
all'albero, quindi il passo induttivo trasforma alberi in alberi.

Dato un albero di cammini minimi, per ogni nodo $v\in V$ definiamo:
\begin{itemize}
\item $v.d = \delta(s,v)$
\item $v.p$ il predecessore di $v$ nel cammino minimo scelto
\end{itemize}

\subsection{Archi non pesati: BFS}

Nel caso in cui tutti gli archi hanno lunghezza $1$ l'albero dei
cammini minimi può essere costruito con una visita in ampiezza (BFS:
breadth-first search).

\begin{algorithmic}
  \For {v $\in$ V}
    \State{v.d = $\infty$}
    \State{v.p = v}
  \EndFor
  \State{s.d = 0}
  \State{q = Queue()}
  \State{q.push(s)}
  \While{ ! q.empty()}
    \State{v = q.pop()}
    \For{u $\in$ v.neigh}
      \If{u.d = $\infty$}
        \State{u.d = v.d + 1}
        \State{u.p = v}
        \State{q.push(u)}
      \EndIf
    \EndFor
  \EndWhile
\end{algorithmic}

Vogliamo dimostrare la correttezza dell'algoritmo. Per farlo definiamo,
ad ogni passaggio dell'algoritmo. TODO

L'algoritmo termina in $\Omega (M)$ infatti ogni nodo viene inserito
ed estratto dalla coda esattamente una volta e ogni arco viene
visitato una volta durante la visita del nodo di di partenza. TODO.

TODO: correttezza

TODO: disegnini

TODO: come trovare tutti i cammini

\subsection{Archi pesati: Dijkstra}

Nel caso in cui gli archi non abbiano tutti lunghezza unitaria, ma
comunque non negativa, dobbiamo usare l'algoritmo di Dijkstra

\begin{algorithmic}
  \For {v $\in$ V}
    \State{v.d = $\infty$}
    \State{v.p = v}
  \EndFor
  \State{S = $\emptyset$}
  \State{s.d = 0}
  \State{q = PriorityQueue()}
  \State{q.push(s,s.d)}
  \While{ ! q.empty()}
    \State{v = q.extract\_min()}
    \State{S = S $\cup$ \{v\}}
    \For{u $\in$ v.neigh}
      \If{u.d > v.d + w((v,u))}
        \State{u.d = v.d + 1}
        \State{u.p = v}
        \State{q.push(u,u.d)}
      \EndIf
    \EndFor
  \EndWhile
\end{algorithmic}

TODO: è corretto

TODO: disegnini

TODO: come trovare tutti i cammini

\section{Cammini minimi fra ogni coppia}

Abbiamo visto che siamo in grado, data una sorgente $s\in V$, di
trovare tutti i cammini minimi da $s$ ad ogni nodo $v\in V$ e di
salvarci le distanze di ogni nodo dalla sorgente fissata. Ripetendo
questo procedimento al variare di $s\in V$ otteniamo questa
informazione per ogni coppia di nodi $(v,u)$ del grafo.

Nel nostro caso (archi di peso non negativo) possiamo applicare
Dijkstra su ogni nodo ottenendo un tempo di $O(NM\log N)$

Ci chiediamo se esiste un metodo più veloce per estrarre alcune di
queste informazioni, possiamo sperare di riuscire a fare di meglio
evitando di fissare la sorgente.

Gli algoritmi che vedremo utilizzeranno la matrice di adiacenza del
grafo, cioè supponiamo i aver numerato i nodi da $0$ a $N-1$, allora
definiamo la matrice di adiacenza di $G$ come la matrice $W$ con
elementi
\[
  w_{i,j} = \left\{
    \begin{matrix}
      0 & \text{se } i = j \\
      w\pa{(i,j)} & \text{se } i\neq j,\; (i,j) \in E \\
      \infty & \text{se } i\neq j,\; (i,j) \not\in E
    \end{matrix}
  \right.
\]

Avendo supposto archi di peso non negativo, questa matrice avrà
elementi non negativi, inoltre se il grafo è indiretto questa matrice
diventa simmetrica.

\subsection{Tabella delle distanze}

%TODO: proprietà della matrice: triangolare

Vogliamo calcolare la matrice delle distanze $D$ che ha per elementi
$d_{i,j} = \delta(i,j)$.

Consideriamo la matrice $L^{(m)}$ dove $l^{(m)}_{i,j}$ è il minimo
peso di un cammino da $i$ a $j$ che utilizzi al più $m$ archi. \`E
evidente che $L^{(N-1)} = D$\footnote{Infatti un cammino minimo al più
  tocca tutti i nodi}, quindi cerchiamo un metodo induttivo per
calcolare $L^{(m)}$.

\textbf{Caso base:} per $m=0$ allora si ha
\[ l^{(0)} _{i,j} = \left\{
  \begin{matrix}
    0 & \text{se } i = j\\
    \infty & \text{se } i \neq j
  \end{matrix}
  \right.
\]

\textbf{Passo induttivo:} supponiamo di conoscere $L^{(m-1)}$, un
cammino con al più $m$ archi da $i$ a $j$ può avere:
\begin{itemize}
\item $m-1$ archi, quindi avrà lunghezza minima $l^{(m-1)}
  _{i,j}$ da cui $l^{(m)}_{i,j} \le l^{(m-1)} _{i,j}$
\item $m$ archi, allora lo possiamo spezzare come un cammino di
  $m-1$ archi (che arriverà ad un nodo che chiamiamo $k$) più un
  cammino di $1$ arco di lunghezza $w\pa{(k,j)}$. Per questo possiamo
  scrivere 
  \[ \forall k \in V\;\;\; l^{(m)}_{i,j} \le l^{(m-1)} _{i,k} + w\pa{
    (k,j) } \]
\end{itemize}
Quindi possiamo scrivere
\[ l^{(m)}_{i,j} = \min\set{ l^{(m-1)} _{i,j} , \min _{0\le k\le N-1}
  \set{ l^{(m-1)} _{i,k} + w_{k,j}} }  =  \min _{0\le k\le N-1}
  \set{ l^{(m-1)} _{i,k} + w_{k,j}} \]
Dove l'ultima uguaglianza possiamo scriverela perché abbiamo imposto
$w_{i,i} = 0$.

Implementando questa procedura impieghiamo $O(N)$ per calcolare un
$l^{(m)}_{i,j}$, $O(N^2)$ per calcolare tutta la matrice $L^{(m)}$ da
cui $O(N^4)$ per risolvere il problema, questo tempo è peggiore di
applicare Dijkstra per ogni sorgente, infatti abbiamo osservato che
con quel metodo si impiega $O(NM\log N) = O( N^3 \log (N) )$ tempo.

Vediamo, però, come leggere l'aggiornamento della matrice $L$ come un
prodotto fra matrici. Ricordiamo che le entrate del prodotto fra
matrici possono essere scritte come
\[ c_{i,j} = \sum _k a_{i,k} \cdot b_{k,j} \] quindi considerando
$\mathbb{R}\cup \set{+\infty}$ con le operazioni di $\min$ e $+$
(rispettivamente al posto di $+$ e $\cdot$) otteniamo che
\[ L^{(m)} = L^{(m-1)} * W \]
dove $*$ è il prodotto di matrici con le nuove operazioni.

$\pa{\mathbb{R}\cup \set{+\infty} ,\min,+}$ ha le seguenti propietà:
\begin{itemize}
\item $\min$ è associativa
\item $\min$ ha elemento neutro $\infty$
\item $\min$ è commutativa
\item $+$ è associativa
\item $+$ ha elemento neutro $0$
\item $+$ è commutativa
\item $+$ è distributiva rispetto a $\min$ (sia a destra che a sinistra)
\end{itemize}

Possiamo scrivere
\begin{align*}
  L^{(1)} & = & L^{(0)} * W & = & W \\
  L^{(1)} & = & L^{(1)} * W & = & W^2 \\
  & & \vdots & & \\
  L^{(N-1)} & = & L^{(N-2)} * W & = & W^{N-1} 
\end{align*}

Allora, visto che non siamo interessati alle matrici intermedie, ma
solo a $L^{(N-1)}$, possiamo calcolare induttivamente $W^{2^k}$ con la
formula
\[ W ^{2^k} = \pa{W ^{2^{k-1}}} ^2 \]
osservando che $L^{(m)} = L^{(N-1)}$ per $m \ge N-1$ si ha
\[ L^{(N-1)} = W^{2 ^{\ceil {\log \pa{ N-1} } } } \]

Siamo riusciti, in questo modo, a ridurre il tempo a $O\pa{ N^3 \log
  (N)}$
simile a quello di Dijkstra nel caso di grafo denso.

Potremmo pensare di migliorare questo metodo utilizzando la
moltiplicazione veloce fra matrici (che impiega $O\pa{pN^\omega}$
tempo dove $p$ è il tempo di un prodotto fra due entrate, $N$ la
dimensione della matrice e $2 \le \omega <3$ un esponente legato al
metodo). In questo caso, però, non lo possiamo applicare direttamente
perché la struttura di $\pa{ \mathbb{R}, \min , +}$ non è un anello in
quanto non esiste un inverso per $\min$.

\subsection{Un cammino per ogni coppia}

\subsection{Tutti i cammini per ogni coppia}

\chapter{Oracoli per distanze}

\section{Oracoli approssimati}

\subsection{Graph spanners}

\subsection{Risultati noti}

\section{Oracoli esatti}

Tutte le distanze in $O(n^2)$ spazio con query costanti

http://www.sciencedirect.com/science/article/pii/S0304397510003130

\subsection{Risuluzione tramite alberi di ricoprimento etichettati}

\subsection{Compressione degli alberi}

\subsection{Compressione delle etichette: Wavelet Tree}

\subsection{Ottimalità}

\subsection{Possibile generalizzazione: archi pesati}


\chapter{Problema dei $k$ cammini minimi}

https://www.ics.uci.edu/~eppstein/pubs/Epp-TR-94-26.pdf

\chapter{Tutti i cammini minimi}

\section{Un primo algoritmo}

$O(n^3)$

\section{Un algoritmo con tempo di query non ottimale}

\subsection{L'algoritmo}

\subsection{Complessità}

\section{Una classe particolare: grafi planari}

\subsection{Separation theorem}

\subsection{Un algoritmo in spazio $O(n^{2.5})$}

$O(n^{2.5})$ con il separation theorem

\section{Un nuovo algoritmo}

???

\section{Un caso difficile}







\end{document}

